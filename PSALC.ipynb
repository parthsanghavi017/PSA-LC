{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73da361d-e3c8-4003-a368-78009b5a4aac",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4877dd84-b909-45a5-beee-8f9a31fd24f1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### LC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32ba4402-b7fd-4d0a-9860-f25bd64b88f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Symbol  HC1  HC2  HC3  HC4  HC5  LC1  HC6  HC7  LC2  ...  LC16  LC17  \\\n",
      "0         OR4F5    0    0    0    0    0    0    0    0    0  ...     0     0   \n",
      "1  LOC112268260    0   32    9   11   14   25   61    8   16  ...    17    17   \n",
      "2        OR4F29    0    0    0    0    0    0    0    0    0  ...     0     0   \n",
      "3  LOC105378947    0    2    1    1    0    2   19    2    0  ...     1     0   \n",
      "4        OR4F16    0   13    3    9    3    5   29    8    5  ...    10    13   \n",
      "\n",
      "   LC18  LC19  HC12  HC13  LC20  LC21  LC22  LC23  \n",
      "0     0     0     0     0     0     0     0     0  \n",
      "1    11     7    26    28    21    20    28    14  \n",
      "2     0     0     1     0     0     0     0     0  \n",
      "3     0     0     1     4     1     0     2     2  \n",
      "4     1     3    12    18    16    15     9     6  \n",
      "\n",
      "[5 rows x 37 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13460\\4227129484.py:5: DtypeWarning: Columns (8,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  annot_df = pd.read_csv(annot_file, sep='\\t')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Read the annotation file\n",
    "annot_file = 'LC/Human.GRCh38.p13.annot.tsv'\n",
    "annot_df = pd.read_csv(annot_file, sep='\\t')\n",
    "\n",
    "# Step 2: Filter for protein-coding genes\n",
    "protein_coding_df = annot_df[annot_df['GeneType'] == 'protein-coding'][['GeneID', 'Symbol']]\n",
    "\n",
    "# Step 3: Read the second TSV file\n",
    "data_file = 'LC/GSE224615_raw_counts_GRCh38.p13_NCBI.tsv'  # Replace with your actual file name\n",
    "data_df = pd.read_csv(data_file, sep='\\t')\n",
    "\n",
    "# Step 4: Merge the dataframes on GeneID\n",
    "merged_df = pd.merge(data_df, protein_coding_df, on='GeneID', how='inner')\n",
    "\n",
    "# Step 5: Drop GeneID and keep Symbol\n",
    "final_df = merged_df.drop(columns=['GeneID'])\n",
    "\n",
    "# Step 6: Reorder columns to have Symbol first\n",
    "cols = ['Symbol'] + [col for col in final_df.columns if col != 'Symbol']\n",
    "final_df = final_df[cols]\n",
    "\n",
    "# Step 7: Save the result to a new TSV file\n",
    "final_df.to_csv('LC/GSE224615_raw_counts_GRCh38.p13_NCBI_processed.tsv', sep='\\t', index=False)\n",
    "\n",
    "# Optional: Display the first few rows\n",
    "print(final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dae3ea4-7fba-4daa-a311-3352f14ffcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Symbol  HC1  HC2  HC3  HC4  HC5  HC6  HC7  LC1  LC2  LC3  LC4  LC5  \\\n",
      "0         OR4F5    0    0    0    0    0    0    0    0    0    0    0    0   \n",
      "1  LOC112268260    2    3    3    6    0    5    3   13    7    5    3    5   \n",
      "2        OR4F29    0    0    0    0    0    0    0    0    0    0    0    0   \n",
      "3  LOC105378947    0    1    0    0    1    3    0    1    0    0    0    1   \n",
      "4        OR4F16    1    0    1    0    0    0    1    1    1    1    1    1   \n",
      "\n",
      "   LC6  LC7  LC8  LC9  LC10  LC11  \n",
      "0    0    0    0    0     0     0  \n",
      "1    9    2    8    5     6     5  \n",
      "2    0    0    0    0     0     0  \n",
      "3    1    1    1    1     1     0  \n",
      "4    0    0    1    1     1     1  \n"
     ]
    }
   ],
   "source": [
    "# Step 3: Read the second TSV file\n",
    "data_file = 'LC/GSE251849_raw_counts_GRCh38.p13_NCBI.tsv'  # Replace with your actual file name\n",
    "data_df = pd.read_csv(data_file, sep='\\t')\n",
    "\n",
    "# Step 4: Merge the dataframes on GeneID\n",
    "merged_df = pd.merge(data_df, protein_coding_df, on='GeneID', how='inner')\n",
    "\n",
    "# Step 5: Drop GeneID and keep Symbol\n",
    "final_df = merged_df.drop(columns=['GeneID'])\n",
    "\n",
    "# Step 6: Reorder columns to have Symbol first\n",
    "cols = ['Symbol'] + [col for col in final_df.columns if col != 'Symbol']\n",
    "final_df = final_df[cols]\n",
    "\n",
    "# Step 7: Save the result to a new TSV file\n",
    "final_df.to_csv('LC/GSE251849_raw_counts_GRCh38.p13_NCBI_processed.tsv', sep='\\t', index=False)\n",
    "\n",
    "# Optional: Display the first few rows\n",
    "print(final_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fce464c-2fed-48a8-8396-5b5123906e18",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### PsA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6730f4a-e56c-4c47-a526-3e153ed35a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13460\\936715413.py:6: DtypeWarning: Columns (8,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  annot_df = pd.read_csv(annot_file, sep='\\t')\n",
      "Input sequence provided is already in string format. No operation performed\n",
      "Input sequence provided is already in string format. No operation performed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation file columns: ['GeneID', 'Symbol', 'Description', 'Synonyms', 'GeneType', 'EnsemblGeneID', 'Status', 'ChrAcc', 'ChrStart', 'ChrStop', 'Orientation', 'Length', 'GOFunctionID', 'GOProcessID', 'GOComponentID', 'GOFunction', 'GOProcess', 'GOComponent']\n",
      "Unique GeneType values: ['pseudo' 'ncRNA' 'protein-coding' nan 'snoRNA' 'snRNA' 'tRNA' 'other'\n",
      " 'unknown' 'rRNA' 'scRNA']\n",
      "Number of protein-coding genes: 19416\n",
      "Missing Symbols in protein-coding annotation: 0\n",
      "CSV columns: ['EnsemblGeneID', 'HC1', 'HC2', 'HC3', 'HC4', 'HC5', 'HC6', 'HC7', 'HC8', 'HC9', 'PA1', 'PA2', 'PA3', 'PA4', 'PA5', 'PA6', 'PA7', 'PA8', 'PA9', 'PA10', 'PA11', 'PA12', 'PA13', 'PA14', 'PA15', 'PA16', 'PA17', 'PA18']\n",
      "Sample EnsemblGeneID: ['ENSG00000282222', 'ENSG00000282221', 'ENSG00000111671', 'ENSG00000110514', 'ENSG00000086015']\n",
      "Total genes in CSV: 58302\n",
      "Rows after merge: 58313\n",
      "Missing Symbols after merge: 39136\n",
      "Number of unmatched EnsemblGeneID: 39136\n",
      "Sample unmatched EnsemblGeneID: ['ENSG00000282222', 'ENSG00000282221', 'ENSG00000211769', 'ENSG00000211768', 'ENSG00000211767']\n",
      "Querying 39136 missing Ensembl IDs with mygene...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30 input query terms found dup hits:\t[('ENSG00000261600', 2), ('ENSG00000277927', 3), ('ENSG00000233656', 2), ('ENSG00000278932', 3), ('E\n",
      "1592 input query terms found no hit:\t['ENSG00000262558', 'ENSG00000262554', 'ENSG00000250567', 'ENSG00000283689', 'ENSG00000259166', 'ENS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved symbols from mygene: 39191\n",
      "Missing Symbols after mygene: 14027\n",
      "CSV with Symbols saved as 'PSA/GSE205748_read_count_processed.csv'\n",
      "  Symbol   HC1   HC2   HC3   HC4   HC5   HC6   HC7   HC8   HC9  ...   PA9  \\\n",
      "0    NaN     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "1    NaN    17    16    10    27    31    27    23    22    21  ...    31   \n",
      "2  SPSB2   157   228   245   274   253   232   327   319   262  ...   151   \n",
      "3   MADD  1308  1727  1989  1017  2042  1662  2042  2075  2106  ...  1697   \n",
      "4  MAST2   822  1229  1352   798  1161  1353  1801  1443  1052  ...   936   \n",
      "\n",
      "   PA10  PA11  PA12  PA13  PA14  PA15  PA16  PA17  PA18  \n",
      "0     0     0     0     0     0     0     0     0     0  \n",
      "1    22    28    15    21    28    16    26    19    18  \n",
      "2   167   250   205   159   344   205   203   222   138  \n",
      "3  1724  2058  1700  1550  1948  2188  2136  1885  1697  \n",
      "4   883   834   667   601   899   750   881   734   832  \n",
      "\n",
      "[5 rows x 28 columns]\n",
      "Unmatched EnsemblGeneID saved to 'PSA/unmatched_ensembl_ids.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mygene\n",
    "\n",
    "# Step 1: Read the annotation file and filter for protein-coding genes\n",
    "annot_file = 'LC/Human.GRCh38.p13.annot.tsv'\n",
    "annot_df = pd.read_csv(annot_file, sep='\\t')\n",
    "\n",
    "# Debug: Check annotation file columns and unique GeneType values\n",
    "print(\"Annotation file columns:\", annot_df.columns.tolist())\n",
    "print(\"Unique GeneType values:\", annot_df['GeneType'].unique())\n",
    "print(\"Number of protein-coding genes:\", len(annot_df[annot_df['GeneType'] == 'protein-coding']))\n",
    "\n",
    "# Filter for protein-coding genes\n",
    "protein_coding_df = annot_df[annot_df['GeneType'] == 'protein-coding'][['EnsemblGeneID', 'Symbol']]\n",
    "# Debug: Check for missing Symbols in annotation\n",
    "print(\"Missing Symbols in protein-coding annotation:\", protein_coding_df['Symbol'].isna().sum())\n",
    "\n",
    "# Step 2: Read the CSV file\n",
    "csv_file = 'PSA/GSE205748_read_counts.csv'\n",
    "ensembl_df = pd.read_csv(csv_file, sep='\\t')\n",
    "ensembl_df.rename(columns={'ID': 'EnsemblGeneID'}, inplace=True)\n",
    "\n",
    "# Debug: Check CSV columns and sample EnsemblGeneID\n",
    "print(\"CSV columns:\", ensembl_df.columns.tolist())\n",
    "print(\"Sample EnsemblGeneID:\", ensembl_df['EnsemblGeneID'].head().tolist())\n",
    "print(\"Total genes in CSV:\", len(ensembl_df))\n",
    "\n",
    "# Step 3: Merge to map EnsemblGeneID to Symbol (use left join to keep all CSV rows)\n",
    "merged_ensembl_df = pd.merge(ensembl_df, protein_coding_df, on='EnsemblGeneID', how='left')\n",
    "\n",
    "# Debug: Check merge results\n",
    "print(\"Rows after merge:\", len(merged_ensembl_df))\n",
    "print(\"Missing Symbols after merge:\", merged_ensembl_df['Symbol'].isna().sum())\n",
    "unmatched_ids = merged_ensembl_df[merged_ensembl_df['Symbol'].isna()]['EnsemblGeneID'].unique()\n",
    "print(\"Number of unmatched EnsemblGeneID:\", len(unmatched_ids))\n",
    "print(\"Sample unmatched EnsemblGeneID:\", unmatched_ids[:5].tolist())\n",
    "\n",
    "# Step 4: Handle missing Symbols with mygene\n",
    "if len(unmatched_ids) > 0:\n",
    "    print(f\"Querying {len(unmatched_ids)} missing Ensembl IDs with mygene...\")\n",
    "    mg = mygene.MyGeneInfo()\n",
    "    try:\n",
    "        gene_info = mg.querymany(unmatched_ids, scopes='ensembl.gene', fields='symbol', species='human', as_dataframe=True)\n",
    "        if not gene_info.empty:\n",
    "            gene_info = gene_info.reset_index()[['query', 'symbol']].rename(columns={'query': 'EnsemblGeneID', 'symbol': 'Symbol'})\n",
    "            print(\"Retrieved symbols from mygene:\", len(gene_info))\n",
    "            # Update missing Symbols\n",
    "            for _, row in gene_info.iterrows():\n",
    "                if pd.notna(row['Symbol']):\n",
    "                    merged_ensembl_df.loc[merged_ensembl_df['EnsemblGeneID'] == row['EnsemblGeneID'], 'Symbol'] = row['Symbol']\n",
    "        else:\n",
    "            print(\"No symbols retrieved from mygene.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Mygene query failed: {e}\")\n",
    "\n",
    "# Debug: Final check for missing Symbols\n",
    "print(\"Missing Symbols after mygene:\", merged_ensembl_df['Symbol'].isna().sum())\n",
    "\n",
    "# Step 5: Drop EnsemblGeneID and reorder columns\n",
    "final_df = merged_ensembl_df.drop(columns=['EnsemblGeneID'])\n",
    "cols = ['Symbol'] + [col for col in final_df.columns if col != 'Symbol']\n",
    "final_df = final_df[cols]\n",
    "\n",
    "# Step 6: Save the updated CSV\n",
    "output_file = 'PSA/GSE205748_read_count_processed.csv'\n",
    "final_df.to_csv(output_file, sep=',', index=False)\n",
    "print(f\"CSV with Symbols saved as '{output_file}'\")\n",
    "print(final_df.head())\n",
    "\n",
    "# Step 7: Save unmatched IDs for inspection\n",
    "if len(unmatched_ids) > 0:\n",
    "    pd.DataFrame(unmatched_ids, columns=['EnsemblGeneID']).to_csv('PSA/unmatched_ensembl_ids.csv', index=False)\n",
    "    print(\"Unmatched EnsemblGeneID saved to 'PSA/unmatched_ensembl_ids.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c3b7f14-e679-4987-b318-b9763654bf8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13460\\1121881149.py:6: DtypeWarning: Columns (8,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  annot_df = pd.read_csv(annot_file, sep='\\t')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of protein-coding genes in TSV: 19213\n",
      "Missing Symbols in TSV protein-coding: 0\n",
      "Number of unique EnsemblGeneID in idmap: 58302\n",
      "Missing Symbols in idmap: 14031\n",
      "Total genes in CSV: 58302\n",
      "Sample EnsemblGeneID: ['ENSG00000282222', 'ENSG00000282221', 'ENSG00000111671', 'ENSG00000110514', 'ENSG00000086015']\n",
      "Rows after TSV merge (protein-coding): 19152\n",
      "Missing Symbols after TSV merge: 0\n",
      "Number of unmatched EnsemblGeneID: 39150\n",
      "Sample unmatched EnsemblGeneID: ['ENSG00000282222', 'ENSG00000282221', 'ENSG00000211769', 'ENSG00000211768', 'ENSG00000211767']\n",
      "Protein-coding genes from idmap: 0\n",
      "CSV with Symbols saved as 'PSA/GSE205748_read_count_processed.csv'\n",
      "    Symbol   HC1   HC2   HC3   HC4   HC5   HC6   HC7   HC8   HC9  ...   PA9  \\\n",
      "0    SPSB2   157   228   245   274   253   232   327   319   262  ...   151   \n",
      "1     MADD  1308  1727  1989  1017  2042  1662  2042  2075  2106  ...  1697   \n",
      "2    MAST2   822  1229  1352   798  1161  1353  1801  1443  1052  ...   936   \n",
      "3  CSNK2A2  3221  5079  5188  5096  4190  5038  5984  6236  6713  ...  3676   \n",
      "4    ZNF32   269   463   480   504   390   635   417   359   363  ...   330   \n",
      "\n",
      "   PA10  PA11  PA12  PA13  PA14  PA15  PA16  PA17  PA18  \n",
      "0   167   250   205   159   344   205   203   222   138  \n",
      "1  1724  2058  1700  1550  1948  2188  2136  1885  1697  \n",
      "2   883   834   667   601   899   750   881   734   832  \n",
      "3  3626  3977  4600  6330  4230  4741  5594  5614  3291  \n",
      "4   219   213   180   212   305   344   232   203   280  \n",
      "\n",
      "[5 rows x 28 columns]\n",
      "Matched EnsemblGeneID saved to 'PSA/matched_ensembl_ids.csv'\n",
      "Unmatched EnsemblGeneID saved to 'PSA/unmatched_ensembl_ids.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mygene\n",
    "\n",
    "# Step 1: Read and deduplicate the annotation TSV\n",
    "annot_file = 'LC/Human.GRCh38.p13.annot.tsv'\n",
    "annot_df = pd.read_csv(annot_file, sep='\\t')\n",
    "# Remove duplicates in EnsemblGeneID\n",
    "annot_df = annot_df.drop_duplicates(subset=['EnsemblGeneID'], keep='first')\n",
    "# Filter for protein-coding genes\n",
    "protein_coding_df = annot_df[annot_df['GeneType'] == 'protein-coding'][['EnsemblGeneID', 'Symbol']]\n",
    "# Strip version suffixes\n",
    "protein_coding_df['EnsemblGeneID'] = protein_coding_df['EnsemblGeneID'].str.split('.').str[0]\n",
    "print(\"Number of protein-coding genes in TSV:\", len(protein_coding_df))\n",
    "print(\"Missing Symbols in TSV protein-coding:\", protein_coding_df['Symbol'].isna().sum())\n",
    "\n",
    "# Step 2: Read and deduplicate the idmap XLSX\n",
    "idmap_file = 'PSA/idmap.xlsx'\n",
    "idmap_df = pd.read_excel(idmap_file)\n",
    "# Remove duplicates in query (EnsemblGeneID)\n",
    "idmap_df = idmap_df.drop_duplicates(subset=['query'], keep='first')\n",
    "# Rename query to EnsemblGeneID and select relevant columns\n",
    "idmap_df = idmap_df[['query', 'symbol']].rename(columns={'query': 'EnsemblGeneID', 'symbol': 'Symbol'})\n",
    "# Strip version suffixes\n",
    "idmap_df['EnsemblGeneID'] = idmap_df['EnsemblGeneID'].str.split('.').str[0]\n",
    "print(\"Number of unique EnsemblGeneID in idmap:\", len(idmap_df))\n",
    "print(\"Missing Symbols in idmap:\", idmap_df['Symbol'].isna().sum())\n",
    "\n",
    "# Step 3: Read the CSV\n",
    "csv_file = 'PSA/GSE205748_read_counts.csv'\n",
    "ensembl_df = pd.read_csv(csv_file, sep='\\t')\n",
    "ensembl_df.rename(columns={'ID': 'EnsemblGeneID'}, inplace=True)\n",
    "# Strip version suffixes\n",
    "ensembl_df['EnsemblGeneID'] = ensembl_df['EnsemblGeneID'].str.split('.').str[0]\n",
    "print(\"Total genes in CSV:\", len(ensembl_df))\n",
    "print(\"Sample EnsemblGeneID:\", ensembl_df['EnsemblGeneID'].head().tolist())\n",
    "\n",
    "# Step 4: Merge with TSV annotation (protein-coding only)\n",
    "merged_df = pd.merge(ensembl_df, protein_coding_df, on='EnsemblGeneID', how='inner')\n",
    "print(\"Rows after TSV merge (protein-coding):\", len(merged_df))\n",
    "print(\"Missing Symbols after TSV merge:\", merged_df['Symbol'].isna().sum())\n",
    "\n",
    "# Step 5: Check unmatched IDs against idmap.xlsx\n",
    "unmatched_ids = ensembl_df[~ensembl_df['EnsemblGeneID'].isin(protein_coding_df['EnsemblGeneID'])]['EnsemblGeneID'].unique()\n",
    "print(\"Number of unmatched EnsemblGeneID:\", len(unmatched_ids))\n",
    "print(\"Sample unmatched EnsemblGeneID:\", unmatched_ids[:5].tolist())\n",
    "\n",
    "# Merge unmatched IDs with idmap.xlsx\n",
    "unmatched_df = pd.DataFrame({'EnsemblGeneID': unmatched_ids})\n",
    "idmap_merged = pd.merge(unmatched_df, idmap_df, on='EnsemblGeneID', how='left')\n",
    "# Filter for protein-coding by cross-referencing with TSV GeneType\n",
    "idmap_protein_coding = idmap_merged[idmap_merged['EnsemblGeneID'].isin(protein_coding_df['EnsemblGeneID'])]\n",
    "print(\"Protein-coding genes from idmap:\", len(idmap_protein_coding))\n",
    "\n",
    "# Step 6: Combine TSV and idmap results\n",
    "# Append idmap protein-coding matches to main merge (if any)\n",
    "if not idmap_protein_coding.empty:\n",
    "    idmap_to_add = pd.merge(ensembl_df, idmap_protein_coding, on='EnsemblGeneID', how='inner')\n",
    "    idmap_to_add = idmap_to_add[ensembl_df.columns.tolist() + ['Symbol']]  # Align columns\n",
    "    merged_df = pd.concat([merged_df, idmap_to_add], ignore_index=True)\n",
    "    print(\"Rows after adding idmap protein-coding:\", len(merged_df))\n",
    "\n",
    "# Step 7: Drop EnsemblGeneID and reorder columns\n",
    "final_df = merged_df.drop(columns=['EnsemblGeneID'])\n",
    "cols = ['Symbol'] + [col for col in final_df.columns if col != 'Symbol']\n",
    "final_df = final_df[cols]\n",
    "\n",
    "# Step 8: Save the output\n",
    "output_file = 'PSA/GSE205748_read_count_processed.csv'\n",
    "final_df.to_csv(output_file, sep=',', index=False)\n",
    "print(f\"CSV with Symbols saved as '{output_file}'\")\n",
    "print(final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54a0636b-450b-488f-b0bf-c96f4aac3af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Gene values: 0\n",
      "Total genes in CSV: 26485\n",
      "Sample Gene values: ['DDX11L1', 'WASH7P', 'MIR6859-3', 'MIR6859-2', 'MIR6859-1']\n",
      "Number of protein-coding genes in TSV: 19416\n",
      "Missing Symbols in TSV protein-coding: 0\n",
      "Rows after merge (protein-coding): 18060\n",
      "Missing Symbols after merge: 0\n",
      "Number of unmatched Gene values: 8425\n",
      "Sample unmatched Gene values: ['DDX11L1', 'WASH7P', 'MIR6859-3', 'MIR6859-2', 'MIR6859-1']\n",
      "Processed CSV saved as 'GSE179800_SKB-counts_processed.csv'\n",
      "   Symbol  PA1  PA2  PA3  PA4\n",
      "0   OR4F5    1    0    0    0\n",
      "1  OR4F29    0    0    0    0\n",
      "2   OR4F3    0    0    0    0\n",
      "3  OR4F16    0    0    0    0\n",
      "4  SAMD11    0    0    0    0\n",
      "Matched genes saved to 'matched_genes.csv'\n",
      "Unmatched genes saved to 'unmatched_genes.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13460\\2942116073.py:19: DtypeWarning: Columns (8,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  annot_df = pd.read_csv(annot_file, sep='\\t')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Read and clean the CSV\n",
    "csv_file = 'PSA/GSE179800_SKB-counts.csv'\n",
    "counts_df = pd.read_csv(csv_file)\n",
    "\n",
    "# Drop the first (index) column\n",
    "counts_df = counts_df.drop(counts_df.columns[0], axis=1)\n",
    "\n",
    "# Check for duplicates in Gene\n",
    "print(\"Duplicate Gene values:\", counts_df['Gene'].duplicated().sum())\n",
    "# Deduplicate, keeping first occurrence\n",
    "counts_df = counts_df.drop_duplicates(subset=['Gene'], keep='first')\n",
    "print(\"Total genes in CSV:\", len(counts_df))\n",
    "print(\"Sample Gene values:\", counts_df['Gene'].head().tolist())\n",
    "\n",
    "# Step 2: Read the annotation TSV and filter for protein-coding genes\n",
    "annot_file = 'LC/Human.GRCh38.p13.annot.tsv'\n",
    "annot_df = pd.read_csv(annot_file, sep='\\t')\n",
    "# Remove duplicates in Symbol\n",
    "annot_df = annot_df.drop_duplicates(subset=['Symbol'], keep='first')\n",
    "# Filter for protein-coding genes\n",
    "protein_coding_df = annot_df[annot_df['GeneType'] == 'protein-coding'][['Symbol']]\n",
    "print(\"Number of protein-coding genes in TSV:\", len(protein_coding_df))\n",
    "print(\"Missing Symbols in TSV protein-coding:\", protein_coding_df['Symbol'].isna().sum())\n",
    "\n",
    "# Step 3: Merge to keep only protein-coding genes\n",
    "merged_df = pd.merge(counts_df, protein_coding_df, left_on='Gene', right_on='Symbol', how='inner')\n",
    "print(\"Rows after merge (protein-coding):\", len(merged_df))\n",
    "print(\"Missing Symbols after merge:\", merged_df['Symbol'].isna().sum())\n",
    "\n",
    "# Step 4: Identify unmatched genes\n",
    "unmatched_genes = counts_df[~counts_df['Gene'].isin(protein_coding_df['Symbol'])]['Gene'].unique()\n",
    "print(\"Number of unmatched Gene values:\", len(unmatched_genes))\n",
    "print(\"Sample unmatched Gene values:\", unmatched_genes[:5].tolist())\n",
    "\n",
    "# Step 5: Prepare output (keep Gene column as Symbol)\n",
    "final_df = merged_df[['Gene', 'PA1', 'PA2', 'PA3', 'PA4']]\n",
    "# Rename Gene to Symbol for clarity\n",
    "final_df = final_df.rename(columns={'Gene': 'Symbol'})\n",
    "\n",
    "# Step 6: Save the output\n",
    "output_file = 'GSE179800_SKB-counts_processed.csv'\n",
    "final_df.to_csv(output_file, sep=',', index=False)\n",
    "print(f\"Processed CSV saved as '{output_file}'\")\n",
    "print(final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efddc29e-dd7d-4815-8465-5361a5e97c6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_12088\\357418843.py:5: DtypeWarning: Columns (8,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  annot_df = pd.read_csv(annot_file, sep='\\t')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of protein-coding genes in TSV: 19416\n",
      "Missing Symbols in TSV protein-coding: 0\n",
      "\n",
      "File: LC/GSE224615_raw_counts_GRCh38.p13_NCBI_processed.tsv\n",
      "Columns: ['Gene', 'HC1', 'HC2', 'HC3', 'HC4', 'HC5', 'LC1', 'HC6', 'HC7', 'LC2', 'HC8', 'LC3', 'LC4', 'LC5', 'LC6', 'LC7', 'HC9', 'LC8', 'LC9', 'LC10', 'HC10', 'HC11', 'LC11', 'LC12', 'LC13', 'LC14', 'LC15', 'LC16', 'LC17', 'LC18', 'LC19', 'HC12', 'HC13', 'LC20', 'LC21', 'LC22', 'LC23']\n",
      "Duplicate Gene values: 0\n",
      "Rows after protein-coding filter: 19416\n",
      "Sample Gene values: ['OR4F5', 'LOC112268260', 'OR4F29', 'LOC105378947', 'OR4F16']\n",
      "Unique Gene symbols: 19416\n",
      "\n",
      "File: LC/GSE251849_raw_counts_GRCh38.p13_NCBI_processed.tsv\n",
      "Columns: ['Gene', 'HC1', 'HC2', 'HC3', 'HC4', 'HC5', 'HC6', 'HC7', 'LC1', 'LC2', 'LC3', 'LC4', 'LC5', 'LC6', 'LC7', 'LC8', 'LC9', 'LC10', 'LC11']\n",
      "Duplicate Gene values: 0\n",
      "Rows after protein-coding filter: 19416\n",
      "Sample Gene values: ['OR4F5', 'LOC112268260', 'OR4F29', 'LOC105378947', 'OR4F16']\n",
      "Unique Gene symbols: 19416\n",
      "\n",
      "File: PSA/GSE205748_read_count_processed.csv\n",
      "Columns: ['Gene', 'HC1', 'HC2', 'HC3', 'HC4', 'HC5', 'HC6', 'HC7', 'HC8', 'HC9', 'PA1', 'PA2', 'PA3', 'PA4', 'PA5', 'PA6', 'PA7', 'PA8', 'PA9', 'PA10', 'PA11', 'PA12', 'PA13', 'PA14', 'PA15', 'PA16', 'PA17', 'PA18']\n",
      "Duplicate Gene values: 0\n",
      "Rows after protein-coding filter: 19152\n",
      "Sample Gene values: ['SPSB2', 'MADD', 'MAST2', 'CSNK2A2', 'ZNF32']\n",
      "Unique Gene symbols: 19152\n",
      "\n",
      "File: PSA/GSE179800_SKB-counts.csv\n",
      "Columns: ['Gene', 'PA1', 'PA2', 'PA3', 'PA4', 'PA5', 'HC06', 'HC07', 'HC1', 'HC15', 'HC23']\n",
      "Duplicate Gene values: 2\n",
      "Rows after protein-coding filter: 18060\n",
      "Sample Gene values: ['OR4F5', 'OR4F29', 'OR4F3', 'OR4F16', 'SAMD11']\n",
      "Unique Gene symbols: 18060\n",
      "\n",
      "Number of common protein-coding Gene symbols: 17998\n",
      "Sample common Gene symbols: ['CBFB', 'RHD', 'MED15', 'NLRP5', 'UBE3A']\n",
      "\n",
      "File: LC/GSE224615_raw_counts_GRCh38.p13_NCBI_processed.tsv\n",
      "Rows after common genes filter: 17998\n",
      "Processed file saved as 'LC/GSE224615_raw_counts_GRCh38.p13_NCBI_processed_common.tsv'\n",
      "     Gene  HC1   HC2   HC3   HC4   HC5   LC1   HC6   HC7   LC2  ...  LC16  \\\n",
      "0   OR4F5    0     0     0     0     0     0     0     0     0  ...     0   \n",
      "2  OR4F29    0     0     0     0     0     0     0     0     0  ...     0   \n",
      "4  OR4F16    0    13     3     9     3     5    29     8     5  ...    10   \n",
      "5  SAMD11    7   280   181   237   140   175   260   175   273  ...   336   \n",
      "6   NOC2L  302  3240  1744  2768  2601  1754  2945  2429  2318  ...  2329   \n",
      "\n",
      "   LC17  LC18  LC19  HC12  HC13  LC20  LC21  LC22  LC23  \n",
      "0     0     0     0     0     0     0     0     0     0  \n",
      "2     0     0     0     1     0     0     0     0     0  \n",
      "4    13     1     3    12    18    16    15     9     6  \n",
      "5   228   131   159   302   192   184   212   161   192  \n",
      "6  2825  2138  1786  2556  2381  2616  2674  2718  2701  \n",
      "\n",
      "[5 rows x 37 columns]\n",
      "\n",
      "File: LC/GSE251849_raw_counts_GRCh38.p13_NCBI_processed.tsv\n",
      "Rows after common genes filter: 17998\n",
      "Processed file saved as 'LC/GSE251849_raw_counts_GRCh38.p13_NCBI_processed_common.tsv'\n",
      "     Gene   HC1   HC2   HC3   HC4   HC5   HC6   HC7   LC1   LC2   LC3   LC4  \\\n",
      "0   OR4F5     0     0     0     0     0     0     0     0     0     0     0   \n",
      "2  OR4F29     0     0     0     0     0     0     0     0     0     0     0   \n",
      "4  OR4F16     1     0     1     0     0     0     1     1     1     1     1   \n",
      "5  SAMD11    82    85    97    78    73    72    67    95    77    67    91   \n",
      "6   NOC2L  2728  2540  2568  2127  2237  2173  1969  2430  1938  2347  2608   \n",
      "\n",
      "    LC5   LC6   LC7   LC8   LC9  LC10  LC11  \n",
      "0     0     0     0     0     0     0     0  \n",
      "2     0     0     0     0     0     0     0  \n",
      "4     1     0     0     1     1     1     1  \n",
      "5   108    73    64    91    64    93    58  \n",
      "6  2657  2449  1984  2700  1698  2634  1827  \n",
      "\n",
      "File: PSA/GSE205748_read_count_processed.csv\n",
      "Rows after common genes filter: 17998\n",
      "Processed file saved as 'PSA/GSE205748_read_count_processed_common.csv'\n",
      "      Gene   HC1   HC2   HC3   HC4   HC5   HC6   HC7   HC8   HC9  ...   PA9  \\\n",
      "0    SPSB2   157   228   245   274   253   232   327   319   262  ...   151   \n",
      "1     MADD  1308  1727  1989  1017  2042  1662  2042  2075  2106  ...  1697   \n",
      "2    MAST2   822  1229  1352   798  1161  1353  1801  1443  1052  ...   936   \n",
      "3  CSNK2A2  3221  5079  5188  5096  4190  5038  5984  6236  6713  ...  3676   \n",
      "4    ZNF32   269   463   480   504   390   635   417   359   363  ...   330   \n",
      "\n",
      "   PA10  PA11  PA12  PA13  PA14  PA15  PA16  PA17  PA18  \n",
      "0   167   250   205   159   344   205   203   222   138  \n",
      "1  1724  2058  1700  1550  1948  2188  2136  1885  1697  \n",
      "2   883   834   667   601   899   750   881   734   832  \n",
      "3  3626  3977  4600  6330  4230  4741  5594  5614  3291  \n",
      "4   219   213   180   212   305   344   232   203   280  \n",
      "\n",
      "[5 rows x 28 columns]\n",
      "\n",
      "File: PSA/GSE179800_SKB-counts.csv\n",
      "Rows after common genes filter: 17998\n",
      "Processed file saved as 'PSA/GSE179800_SKB-counts_common.csv'\n",
      "     Gene  PA1  PA2  PA3  PA4  PA5  HC06  HC07  HC1  HC15  HC23\n",
      "0   OR4F5    1    0    0    0    0     0     1    0     0     0\n",
      "1  OR4F29    0    0    0    0    0     0     0    0     0     0\n",
      "2   OR4F3    0    0    0    0    0     0     0    0     0     0\n",
      "3  OR4F16    0    0    0    0    0     0     0    0     0     0\n",
      "4  SAMD11    0    0    0    0    0     0     0    0     0     0\n",
      "Common Gene symbols saved to 'common_gene_symbols.csv'\n",
      "Unmatched genes for LC/GSE224615_raw_counts_GRCh38.p13_NCBI_processed.tsv saved to 'LC/GSE224615_raw_counts_GRCh38.p13_NCBI_processed_unmatched.tsv'\n",
      "Unmatched genes for LC/GSE251849_raw_counts_GRCh38.p13_NCBI_processed.tsv saved to 'LC/GSE251849_raw_counts_GRCh38.p13_NCBI_processed_unmatched.tsv'\n",
      "Unmatched genes for PSA/GSE205748_read_count_processed.csv saved to 'PSA/GSE205748_read_count_processed_unmatched.csv'\n",
      "Unmatched genes for PSA/GSE179800_SKB-counts.csv saved to 'PSA/GSE179800_SKB-counts_unmatched.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Read the annotation TSV and filter for protein-coding genes\n",
    "annot_file = 'LC/Human.GRCh38.p13.annot.tsv'\n",
    "annot_df = pd.read_csv(annot_file, sep='\\t')\n",
    "# Remove duplicates in Symbol\n",
    "annot_df = annot_df.drop_duplicates(subset=['Symbol'], keep='first')\n",
    "protein_coding_df = annot_df[annot_df['GeneType'] == 'protein-coding'][['Symbol']]\n",
    "print(\"Number of protein-coding genes in TSV:\", len(protein_coding_df))\n",
    "print(\"Missing Symbols in TSV protein-coding:\", protein_coding_df['Symbol'].isna().sum())\n",
    "\n",
    "# Step 2: Load and clean each file\n",
    "files = {\n",
    "    'LC/GSE224615_raw_counts_GRCh38.p13_NCBI_processed.tsv': {'type': 'tsv', 'sep': '\\t'},\n",
    "    'LC/GSE251849_raw_counts_GRCh38.p13_NCBI_processed.tsv': {'type': 'tsv', 'sep': '\\t'},\n",
    "    'PSA/GSE205748_read_count_processed.csv': {'type': 'csv', 'sep': ','},\n",
    "    'PSA/GSE179800_SKB-counts.csv': {'type': 'csv', 'sep': ','}\n",
    "}\n",
    "\n",
    "dfs = {}\n",
    "gene_sets = {}\n",
    "for file_path, config in files.items():\n",
    "    # Read file\n",
    "    df = pd.read_csv(file_path, sep=config['sep'])\n",
    "    \n",
    "    # Debug: Print columns\n",
    "    print(f\"\\nFile: {file_path}\")\n",
    "    print(\"Columns:\", df.columns.tolist())\n",
    "    \n",
    "    # Rename first column to Gene if needed\n",
    "    if df.columns[0].lower() in ['symbol', 'id', 'geneid']:\n",
    "        df = df.rename(columns={df.columns[0]: 'Gene'})\n",
    "    elif df.columns[0] != 'Gene':\n",
    "        print(f\"Warning: First column in {file_path} is '{df.columns[0]}', assuming it's Gene\")\n",
    "        df = df.rename(columns={df.columns[0]: 'Gene'})\n",
    "    \n",
    "    # Check for duplicates\n",
    "    print(\"Duplicate Gene values:\", df['Gene'].duplicated().sum())\n",
    "    df = df.drop_duplicates(subset=['Gene'], keep='first')\n",
    "    \n",
    "    # Filter for protein-coding genes\n",
    "    df = pd.merge(df, protein_coding_df, left_on='Gene', right_on='Symbol', how='inner')\n",
    "    df = df.drop(columns=['Symbol'])  # Drop extra Symbol column\n",
    "    print(\"Rows after protein-coding filter:\", len(df))\n",
    "    print(\"Sample Gene values:\", df['Gene'].head().tolist())\n",
    "    \n",
    "    # Store DataFrame and gene set\n",
    "    dfs[file_path] = df\n",
    "    gene_sets[file_path] = set(df['Gene'])\n",
    "    print(\"Unique Gene symbols:\", len(gene_sets[file_path]))\n",
    "\n",
    "# Step 3: Find overlapping Gene symbols\n",
    "common_genes = set.intersection(*gene_sets.values())\n",
    "print(\"\\nNumber of common protein-coding Gene symbols:\", len(common_genes))\n",
    "print(\"Sample common Gene symbols:\", list(common_genes)[:5])\n",
    "\n",
    "# Step 4: Subset each file to common Gene symbols\n",
    "for file_path, df in dfs.items():\n",
    "    # Filter to common genes\n",
    "    df_common = df[df['Gene'].isin(common_genes)]\n",
    "    print(f\"\\nFile: {file_path}\")\n",
    "    print(\"Rows after common genes filter:\", len(df_common))\n",
    "    \n",
    "    # Save processed file\n",
    "    output_file = file_path.replace('.tsv', '_common.tsv').replace('.csv', '_common.csv')\n",
    "    df_common.to_csv(output_file, sep=files[file_path]['sep'], index=False)\n",
    "    print(f\"Processed file saved as '{output_file}'\")\n",
    "    print(df_common.head())\n",
    "\n",
    "# Step 5: Save common and unmatched genes\n",
    "pd.DataFrame(list(common_genes), columns=['Gene']).to_csv('common_gene_symbols.csv', index=False)\n",
    "print(\"Common Gene symbols saved to 'common_gene_symbols.csv'\")\n",
    "\n",
    "# Save unmatched genes per file\n",
    "for file_path, gene_set in gene_sets.items():\n",
    "    unmatched = gene_set - common_genes\n",
    "    pd.DataFrame(list(unmatched), columns=['Gene']).to_csv(\n",
    "        file_path.replace('.tsv', '_unmatched.tsv').replace('.csv', '_unmatched.csv'),\n",
    "        index=False\n",
    "    )\n",
    "    print(f\"Unmatched genes for {file_path} saved to '{file_path.replace('.tsv', '_unmatched.tsv').replace('.csv', '_unmatched.csv')}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc0d9f0-1b8f-413f-9af2-bc00665e42bb",
   "metadata": {},
   "source": [
    "### DEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d86b28ec-0a51-42c4-8e3a-c97bbde25b8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'DESeq2' was built under R version 4.2.2\"\n",
      "Loading required package: S4Vectors\n",
      "\n",
      "Warning message:\n",
      "\"package 'S4Vectors' was built under R version 4.2.2\"\n",
      "Loading required package: stats4\n",
      "\n",
      "Loading required package: BiocGenerics\n",
      "\n",
      "Warning message:\n",
      "\"package 'BiocGenerics' was built under R version 4.2.1\"\n",
      "\n",
      "Attaching package: 'BiocGenerics'\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    IQR, mad, sd, var, xtabs\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    anyDuplicated, aperm, append, as.data.frame, basename, cbind,\n",
      "    colnames, dirname, do.call, duplicated, eval, evalq, Filter, Find,\n",
      "    get, grep, grepl, intersect, is.unsorted, lapply, Map, mapply,\n",
      "    match, mget, order, paste, pmax, pmax.int, pmin, pmin.int,\n",
      "    Position, rank, rbind, Reduce, rownames, sapply, setdiff, sort,\n",
      "    table, tapply, union, unique, unsplit, which.max, which.min\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: 'S4Vectors'\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    expand.grid, I, unname\n",
      "\n",
      "\n",
      "Loading required package: IRanges\n",
      "\n",
      "Warning message:\n",
      "\"package 'IRanges' was built under R version 4.2.1\"\n",
      "\n",
      "Attaching package: 'IRanges'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:grDevices':\n",
      "\n",
      "    windows\n",
      "\n",
      "\n",
      "Loading required package: GenomicRanges\n",
      "\n",
      "Warning message:\n",
      "\"package 'GenomicRanges' was built under R version 4.2.2\"\n",
      "Loading required package: GenomeInfoDb\n",
      "\n",
      "Warning message:\n",
      "\"package 'GenomeInfoDb' was built under R version 4.2.2\"\n",
      "Loading required package: SummarizedExperiment\n",
      "\n",
      "Warning message:\n",
      "\"package 'SummarizedExperiment' was built under R version 4.2.1\"\n",
      "Loading required package: MatrixGenerics\n",
      "\n",
      "Warning message:\n",
      "\"package 'MatrixGenerics' was built under R version 4.2.1\"\n",
      "Loading required package: matrixStats\n",
      "\n",
      "Warning message:\n",
      "\"package 'matrixStats' was built under R version 4.2.3\"\n",
      "\n",
      "Attaching package: 'MatrixGenerics'\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:matrixStats':\n",
      "\n",
      "    colAlls, colAnyNAs, colAnys, colAvgsPerRowSet, colCollapse,\n",
      "    colCounts, colCummaxs, colCummins, colCumprods, colCumsums,\n",
      "    colDiffs, colIQRDiffs, colIQRs, colLogSumExps, colMadDiffs,\n",
      "    colMads, colMaxs, colMeans2, colMedians, colMins, colOrderStats,\n",
      "    colProds, colQuantiles, colRanges, colRanks, colSdDiffs, colSds,\n",
      "    colSums2, colTabulates, colVarDiffs, colVars, colWeightedMads,\n",
      "    colWeightedMeans, colWeightedMedians, colWeightedSds,\n",
      "    colWeightedVars, rowAlls, rowAnyNAs, rowAnys, rowAvgsPerColSet,\n",
      "    rowCollapse, rowCounts, rowCummaxs, rowCummins, rowCumprods,\n",
      "    rowCumsums, rowDiffs, rowIQRDiffs, rowIQRs, rowLogSumExps,\n",
      "    rowMadDiffs, rowMads, rowMaxs, rowMeans2, rowMedians, rowMins,\n",
      "    rowOrderStats, rowProds, rowQuantiles, rowRanges, rowRanks,\n",
      "    rowSdDiffs, rowSds, rowSums2, rowTabulates, rowVarDiffs, rowVars,\n",
      "    rowWeightedMads, rowWeightedMeans, rowWeightedMedians,\n",
      "    rowWeightedSds, rowWeightedVars\n",
      "\n",
      "\n",
      "Loading required package: Biobase\n",
      "\n",
      "Warning message:\n",
      "\"package 'Biobase' was built under R version 4.2.1\"\n",
      "Welcome to Bioconductor\n",
      "\n",
      "    Vignettes contain introductory material; view with\n",
      "    'browseVignettes()'. To cite Bioconductor, see\n",
      "    'citation(\"Biobase\")', and for packages 'citation(\"pkgname\")'.\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: 'Biobase'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:MatrixGenerics':\n",
      "\n",
      "    rowMedians\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:matrixStats':\n",
      "\n",
      "    anyMissing, rowMedians\n",
      "\n",
      "\n",
      "Warning message:\n",
      "\"package 'dplyr' was built under R version 4.2.3\"\n",
      "\n",
      "Attaching package: 'dplyr'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:Biobase':\n",
      "\n",
      "    combine\n",
      "\n",
      "\n",
      "The following object is masked from 'package:matrixStats':\n",
      "\n",
      "    count\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:GenomicRanges':\n",
      "\n",
      "    intersect, setdiff, union\n",
      "\n",
      "\n",
      "The following object is masked from 'package:GenomeInfoDb':\n",
      "\n",
      "    intersect\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:IRanges':\n",
      "\n",
      "    collapse, desc, intersect, setdiff, slice, union\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:S4Vectors':\n",
      "\n",
      "    first, intersect, rename, setdiff, setequal, union\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:BiocGenerics':\n",
      "\n",
      "    combine, intersect, setdiff, union\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n",
      "Warning message:\n",
      "\"package 'EnhancedVolcano' was built under R version 4.2.1\"\n",
      "Loading required package: ggrepel\n",
      "\n",
      "Warning message:\n",
      "\"package 'ggrepel' was built under R version 4.2.3\"\n",
      "Warning message:\n",
      "\"package 'pheatmap' was built under R version 4.2.3\"\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "library(DESeq2)\n",
    "library(dplyr)\n",
    "library(ggplot2)\n",
    "library(EnhancedVolcano)\n",
    "library(pheatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d72cf70-d97f-40a0-bac0-13a5d293d6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSE224615 dimensions: 17998 36 \n",
      "GSE251849 dimensions: 17998 18 \n"
     ]
    }
   ],
   "source": [
    "# Step 1: Read datasets\n",
    "gse224615 <- read.csv(\"LC/GSE224615_raw_counts_GRCh38.p13_NCBI_processed_common.tsv\", sep=\"\\t\", row.names=1, check.names=FALSE)\n",
    "gse251849 <- read.csv(\"LC/GSE251849_raw_counts_GRCh38.p13_NCBI_processed_common.tsv\", sep=\"\\t\", row.names=1, check.names=FALSE)\n",
    "cat(\"GSE224615 dimensions:\", dim(gse224615), \"\\n\")\n",
    "cat(\"GSE251849 dimensions:\", dim(gse251849), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c27a8fe2-7411-43b1-a6ff-cfc5e6785c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify gene alignment\n",
    "if (!identical(rownames(gse224615), rownames(gse251849))) {\n",
    "  common_genes <- intersect(rownames(gse224615), rownames(gse251849))\n",
    " gse224615 <- gse224615[common_genes, ]\n",
    "  gse251849 <- gse251849[common_genes, ]\n",
    "  cat(\"Aligned to common genes:\", length(common_genes), \"\\n\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cca96e71-8d74-4b10-a0bc-fc008c26eec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged count data dimensions: 17998 54 \n"
     ]
    }
   ],
   "source": [
    "# Step 2: Merge datasets\n",
    "count_data <- cbind(gse251849 ,gse224615)  \n",
    "cat(\"Merged count data dimensions:\", dim(count_data), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6060976-6837-43b5-be12-ad35fb13965e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample counts:\n",
      "\n",
      "  Healthy LongCOVID \n",
      "       20        34 \n"
     ]
    }
   ],
   "source": [
    "# Step 3: Prepare metadata\n",
    "samples <- colnames(count_data)\n",
    "condition <- ifelse(grepl(\"^HC\", samples, ignore.case=TRUE), \"Healthy\",\n",
    "                   ifelse(grepl(\"^LC\", samples, ignore.case=TRUE), \"LongCOVID\", NA))\n",
    "if (any(is.na(condition))) {\n",
    "  stop(\"Some samples lack HC or LC prefix: \", paste(samples[is.na(condition)], collapse=\", \"))\n",
    "}\n",
    "col_data <- data.frame(\n",
    "  sample = samples,\n",
    "  condition = factor(condition, levels=c(\"Healthy\", \"LongCOVID\")),\n",
    "  row.names = samples\n",
    ")\n",
    "cat(\"Sample counts:\\n\")\n",
    "print(table(col_data$condition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6073284e-f145-4a45-89f6-26d1444a9f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count data verified as integers\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Verify raw counts\n",
    "if (any(count_data < 0 | count_data %% 1 != 0)) {\n",
    "  stop(\"Count data contains non-integer or negative values\")\n",
    "}\n",
    "cat(\"Count data verified as integers\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44b1632b-e9b9-4a06-b26e-d5c0cf4236c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "converting counts to integer mode\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Create DESeq2 dataset\n",
    "dds <- DESeqDataSetFromMatrix(\n",
    "  countData = round(count_data),\n",
    "  colData = col_data,\n",
    "  design = ~ condition\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c333f002-270f-4f08-a61b-6a2a501939ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove genes with very low read counts\n",
    "keep <- rowSums(counts(dds)) >= 10\n",
    "dds <- dds[keep,]\n",
    "\n",
    "#make control as 1st i.e. reference level\n",
    "dds$condition <- relevel(dds$condition, ref = \"Healthy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b11d0e93-3031-4af6-a906-35ac992a3674",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "estimating size factors\n",
      "\n",
      "estimating dispersions\n",
      "\n",
      "gene-wise dispersion estimates\n",
      "\n",
      "mean-dispersion relationship\n",
      "\n",
      "final dispersion estimates\n",
      "\n",
      "fitting model and testing\n",
      "\n",
      "-- replacing outliers and refitting for 1932 genes\n",
      "-- DESeq argument 'minReplicatesForReplace' = 7 \n",
      "-- original counts are preserved in counts(dds)\n",
      "\n",
      "estimating dispersions\n",
      "\n",
      "fitting model and testing\n",
      "\n",
      "using 'apeglm' for LFC shrinkage. If used in published research, please cite:\n",
      "    Zhu, A., Ibrahim, J.G., Love, M.I. (2018) Heavy-tailed prior distributions for\n",
      "    sequence count data: removing the noise and preserving large differences.\n",
      "    Bioinformatics. https://doi.org/10.1093/bioinformatics/bty895\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "out of 17152 with nonzero total read count\n",
      "adjusted p-value < 0.1\n",
      "LFC > 0 (up)       : 0, 0%\n",
      "LFC < 0 (down)     : 0, 0%\n",
      "outliers [1]       : 0, 0%\n",
      "low counts [2]     : 93, 0.54%\n",
      "(mean count < 0)\n",
      "[1] see 'cooksCutoff' argument of ?results\n",
      "[2] see 'independentFiltering' argument of ?results\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Run DESeq2\n",
    "dds <- DESeq(dds)\n",
    "results <- lfcShrink(dds, coef=\"condition_LongCOVID_vs_Healthy\", type=\"apeglm\")\n",
    "summary(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01436b51-f8d8-43c4-81c4-7dc9380d3306",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in UseMethod(\"filter\"): no applicable method for 'filter' applied to an object of class \"c('DESeqResults', 'DFrame', 'DataFrame', 'SimpleList', 'RectangularData', 'List', 'DataFrame_OR_NULL', 'Vector', 'list_OR_List', 'Annotated', 'vector_OR_Vector')\"\n",
     "output_type": "error",
     "traceback": [
      "Error in UseMethod(\"filter\"): no applicable method for 'filter' applied to an object of class \"c('DESeqResults', 'DFrame', 'DataFrame', 'SimpleList', 'RectangularData', 'List', 'DataFrame_OR_NULL', 'Vector', 'list_OR_List', 'Annotated', 'vector_OR_Vector')\"\nTraceback:\n",
      "1. filter(., padj < deg_thresholds$padj & abs(log2FoldChange) > \n .     deg_thresholds$log2FoldChange & !is.na(padj))",
      "2. .handleSimpleError(function (cnd) \n . {\n .     watcher$capture_plot_and_output()\n .     cnd <- sanitize_call(cnd)\n .     watcher$push(cnd)\n .     switch(on_error, continue = invokeRestart(\"eval_continue\"), \n .         stop = invokeRestart(\"eval_stop\"), error = NULL)\n . }, \"no applicable method for 'filter' applied to an object of class \\\"c('DESeqResults', 'DFrame', 'DataFrame', 'SimpleList', 'RectangularData', 'List', 'DataFrame_OR_NULL', 'Vector', 'list_OR_List', 'Annotated', 'vector_OR_Vector')\\\"\", \n .     base::quote(UseMethod(\"filter\")))"
     ]
    }
   ],
   "source": [
    "# Step 7: Filter significant DEGs\n",
    "deg_thresholds <- list(\n",
    "  padj = 0.05,\n",
    "  log2FoldChange = 1.5\n",
    ")\n",
    "deg_results <- results %>%\n",
    "  filter(padj < deg_thresholds$padj & abs(log2FoldChange) > deg_thresholds$log2FoldChange & !is.na(padj))\n",
    "cat(\"Number of significant DEGs (padj <\", deg_thresholds$padj, \", |log2FC| >\", deg_thresholds$log2FoldChange, \"):\", nrow(deg_results), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "899bc780-7fce-4d06-a043-292e45cbf21b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in is.data.frame(x): object 'deg_results' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in is.data.frame(x): object 'deg_results' not found\nTraceback:\n",
      "1. eval.parent(Call)",
      "2. eval(expr, p)",
      "3. eval(expr, p)",
      "4. utils::write.table(deg_results, \"significant_degs_HC_vs_LC.csv\", \n .     row.names = FALSE, col.names = TRUE, sep = \",\", dec = \".\", \n .     qmethod = \"double\")",
      "5. is.data.frame(x)",
      "6. .handleSimpleError(function (cnd) \n . {\n .     watcher$capture_plot_and_output()\n .     cnd <- sanitize_call(cnd)\n .     watcher$push(cnd)\n .     switch(on_error, continue = invokeRestart(\"eval_continue\"), \n .         stop = invokeRestart(\"eval_stop\"), error = NULL)\n . }, \"object 'deg_results' not found\", base::quote(is.data.frame(x)))"
     ]
    }
   ],
   "source": [
    "# Step 8: Save results\n",
    "write.csv(results, \"deg_results_HC_vs_LC.csv\", row.names=FALSE)\n",
    "write.csv(deg_results, \"significant_degs_HC_vs_LC.csv\", row.names=FALSE)\n",
    "cat(\"DEG results saved to 'deg_results_HC_vs_LC.csv' and 'significant_degs_HC_vs_LC.csv'\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "108dc501-3fb2-4a16-979e-e1bfe8367889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volcano plot saved to 'volcano_plot_HC_vs_LC.png'\n"
     ]
    }
   ],
   "source": [
    "# Step 10: Visualize results\n",
    "# Volcano plot\n",
    "volcano_plot <- EnhancedVolcano(\n",
    "  results,\n",
    "  lab = results$Gene,\n",
    "  x = \"log2FoldChange\",\n",
    "  y = \"padj\",\n",
    "  pCutoff = deg_thresholds$padj,\n",
    "  FCcutoff = deg_thresholds$log2FoldChange,\n",
    "  title = \"Healthy vs. Long COVID Differential Expression\",\n",
    "  subtitle = \"Volcano Plot\",\n",
    "  pointSize = 2,\n",
    "  labSize = 3,\n",
    "  max.overlaps = 20\n",
    ")\n",
    "ggsave(\"volcano_plot_HC_vs_LC.png\", volcano_plot, width=8, height=6)\n",
    "cat(\"Volcano plot saved to 'volcano_plot_HC_vs_LC.png'\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7c48f3a-095a-4e33-ac2e-0212f319350f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No significant DEGs for heatmap\n"
     ]
    }
   ],
   "source": [
    "# Heatmap of top DEGs\n",
    "top_degs <- head(deg_results, 20)$Gene\n",
    "if (length(top_degs) > 0) {\n",
    "  top_counts <- norm_counts[top_degs, ]\n",
    "  pheatmap(\n",
    "    top_counts,\n",
    "    scale = \"row\",\n",
    "    clustering_distance_rows = \"euclidean\",\n",
    "    clustering_distance_cols = \"euclidean\",\n",
    "    main = \"Top 20 DEGs: Healthy vs. Long COVID\",\n",
    "    filename = \"heatmap_top_degs_HC_vs_LC.png\",\n",
    "    width = 8,\n",
    "    height = 6\n",
    "  )\n",
    "  cat(\"Heatmap saved to 'heatmap_top_degs_HC_vs_LC.png'\\n\")\n",
    "} else {\n",
    "  cat(\"No significant DEGs for heatmap\\n\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e297dabb-d598-4491-a173-7bc3aac71acb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R-ker",
   "language": "R",
   "name": "r"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
